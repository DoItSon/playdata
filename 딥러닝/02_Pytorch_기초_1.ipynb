{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1FApSvFsFH63CrkS8p_pto4MHRloLDYsb",
      "authorship_tag": "ABX9TyOmxCMqOQdLtZcL8DHk52OO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoItSon/playdata/blob/main/%EB%94%A5%EB%9F%AC%EB%8B%9D/02_Pytorch_%EA%B8%B0%EC%B4%88_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- TPU는 아직까지 불안정하다."
      ],
      "metadata": {
        "id": "JqUcqDMjaSAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pytorch\n",
        "- 구글의 tensorflow와 유사한 딥러닝 라이브러리\n",
        "- 페이스북 인공지능 연구팀에 의해 주로 개발 (개발자들 위한 다양한 프레임워크가 나온다.)\n",
        "- torch\n",
        "    - 텐서 변환 및 다양한 수학 함수와 클래스가 들어가 있다.\n",
        "- torch.nn\n",
        "    - 신경망을 구축하기위한 레이어(층), 활성화 함수, 손실함수 등이 들어있다.\n",
        "- torch.utils.data\n",
        "    - 미니배치 학습을 위한 데이터 셋을 구성하는 클래스들이 들어가 있다.\n",
        "- torch.optim\n",
        "    - optimizer 관련된 함수와 클래스가 있다."
      ],
      "metadata": {
        "id": "pyALRRxOa0Ft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "# from torch import nn 으로 사용된다.\n",
        "# 텐서플로우 keras가 좋지만 자유로운 인공지능 만들기에는 부족하다. (연구자들이 파이토치를 많이쓰기 때문에 최신모델 사용하기 좋다.)\n"
      ],
      "metadata": {
        "id": "sC30yANVbBEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 텐서(Tensor)\n",
        "- N-차원 배열\n",
        "- 텐서는 다차원 배열이나 행렬과 매우 유사한 특수한 자료구조\n",
        "- Pytorch 에서는 텐서를 딥러닝 모델의 입력과 출력으로 하여 학습을 진행"
      ],
      "metadata": {
        "id": "f4JxAfjsc6OQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 텐서 만들기"
      ],
      "metadata": {
        "id": "I-grvaerduhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tensor 함수\n",
        "    - 입력받은 데이터를 텐서 객체로 반환"
      ],
      "metadata": {
        "id": "BbDL56G7dhr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [\n",
        "    [1,2,3],\n",
        "    [4,5,6]\n",
        "]\n",
        "x = torch.tensor(data)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYb6b0Sjdxj8",
        "outputId": "631ecf73-54df-43dc-d196-e8d4b6b7b002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omx4heu1eB3O",
        "outputId": "018da61c-9091-4b43-85fe-24904b7813ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype # 확인해야하는 일이 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r13ZXxl3eOlC",
        "outputId": "c074c326-c094-41cd-a779-a88569e1a1d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.array(data)\n",
        "torch.tensor(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44OnB9hUeTHW",
        "outputId": "b3f37083-2e60-4e6f-adf1-ef2018d34ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9r7cHubec3I",
        "outputId": "345ab283-f5cb-45ce-968a-448568d95725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensors 클래스\n",
        "    - 입력받은 데이터를 텐서 객체로 반환\n",
        "    - 다른점은 데이터 타입을 float32 로 변경해준다. (GPU에서 무조건 바꿔주어야 한다.)"
      ],
      "metadata": {
        "id": "DrQsBPT_ernG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(arr)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9RgPSTe7kp",
        "outputId": "21e71784-bb19-470c-e06a-80c751915f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 슬라이싱, 인덱싱, 마스킹 해보기!\n",
        "- ones, zeros"
      ],
      "metadata": {
        "id": "G0IwDVaLfMUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ones_tensor = torch.ones(2,3) # 1로 2행 3열이 채워진다.\n",
        "ones_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVBWpXOHjlK1",
        "outputId": "68dee81d-9c01-41ee-f4fa-e3f159a4d549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros_tensor = torch.zeros(2,3)\n",
        "zeros_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m00-QPqXkP2A",
        "outputId": "56643f00-2ea5-4f7c-bf1f-7e3410fc3aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[:,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVDYY_vXiu6i",
        "outputId": "d0e18dfd-6783-4e6e-9fcd-dc2167e8443c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[x>3] # 마스킹"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjpRUwVGit6S",
        "outputId": "ed7b4419-e8f1-4245-f8a8-aff84484cba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4., 5., 6.])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([ones_tensor,zeros_tensor],dim = 1) # dim = axis 1과 같다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSKDRY0yittD",
        "outputId": "ce5722e5-d977-41b1-b89e-d384f3ff70f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 0., 0., 0.],\n",
              "        [1., 1., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 차원 변경\n",
        "-  view 메소드\n",
        "    - 원소의 순서대로 차원을 변경해서 반환"
      ],
      "metadata": {
        "id": "uMe0YTx9itrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(arr)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnMfnrqeitpi",
        "outputId": "817dc0ff-b070-4994-9437-e48c0cbc9e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_view = x.view(3,2) # reshape과 비슷\n",
        "x_view"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7nIG_Gfitnz",
        "outputId": "be750e8b-6f5a-4a5a-a319-35e888396056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.],\n",
              "        [5., 6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_view[0,0] = 100 # 원본 데이터 유실과 상관없다."
      ],
      "metadata": {
        "id": "xQvQCdo_itl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x # 메모리를 공유하기 때문에 원본 데이터가 유실될 수 있다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik7vceckitjy",
        "outputId": "d80f5687-afce-40fa-e21c-b446412234c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100.,   2.,   3.],\n",
              "        [  4.,   5.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.reshape(3,2) # 복사본을 반환할지 원본을 반환할지에 대해 알 수 없다. 그래서 view를 쓴다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaWNp1-Mithq",
        "outputId": "de3ba9df-d235-4499-9b16-86d1e3a467ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100.,   2.],\n",
              "        [  3.,   4.],\n",
              "        [  5.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 복사하기"
      ],
      "metadata": {
        "id": "MVFKxZ3pite6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.clone()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6TM0Jabitci",
        "outputId": "ae749ed6-4aa5-4598-b287-7020f7445d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100.,   2.,   3.],\n",
              "        [  4.,   5.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- transpose 메소드\n",
        "    - 차원 맞바꾸기\n",
        "    - 두개의 차원만 가능"
      ],
      "metadata": {
        "id": "BTFkg2K7itaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3T8NLXkmp_P",
        "outputId": "9c8747ff-cac4-452f-db4c-eeef7a70b8d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100.,   2.,   3.],\n",
              "        [  4.,   5.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.transpose(0,1) # 0번째와 1번째를 바꾸겠다는 의미"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0ro_xAAitYi",
        "outputId": "4d1e618a-ecc0-456c-e859-27814673ac9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[100.,   4.],\n",
              "        [  2.,   5.],\n",
              "        [  3.,   6.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- permute 메소드\n",
        "    - 여러개 차원 맞바꾸기"
      ],
      "metadata": {
        "id": "nFlYOfN-itWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(1,25).reshape(2,3,4)\n",
        "arr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAn-19RXitT6",
        "outputId": "615d723f-0cd6-49e2-d023-31e1ec0d1671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1,  2,  3,  4],\n",
              "        [ 5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15, 16],\n",
              "        [17, 18, 19, 20],\n",
              "        [21, 22, 23, 24]]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor(arr)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzg_RvIHitRi",
        "outputId": "c1c1e2eb-08c9-4121-c196-199bcb2de3eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.],\n",
              "         [ 9., 10., 11., 12.]],\n",
              "\n",
              "        [[13., 14., 15., 16.],\n",
              "         [17., 18., 19., 20.],\n",
              "         [21., 22., 23., 24.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.permute(0,2,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zr7JUfxnVn1",
        "outputId": "8a4c9090-4a8d-4967-9958-81b7a10d3ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  5.,  9.],\n",
              "         [ 2.,  6., 10.],\n",
              "         [ 3.,  7., 11.],\n",
              "         [ 4.,  8., 12.]],\n",
              "\n",
              "        [[13., 17., 21.],\n",
              "         [14., 18., 22.],\n",
              "         [15., 19., 23.],\n",
              "         [16., 20., 24.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습에 사용할 CPU or GPU 장치 확인"
      ],
      "metadata": {
        "id": "_LeSX9kBnYbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # True가 나오면 GPU가 존재한다는 의미\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HgJ9xVdUn1m3",
        "outputId": "ba4dfb4a-b5e7-4a70-f260-e2a6d58a686d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서를 gpu로 이동시키기"
      ],
      "metadata": {
        "id": "kGxNxvfAn-dB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to(device)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRqFPNQdoeKA",
        "outputId": "e674fc87-535f-4357-d7bb-3c6b4ee1c256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.],\n",
              "         [ 9., 10., 11., 12.]],\n",
              "\n",
              "        [[13., 14., 15., 16.],\n",
              "         [17., 18., 19., 20.],\n",
              "         [21., 22., 23., 24.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 텐서가 위차한 장치 확인하기"
      ],
      "metadata": {
        "id": "TT5V8m9Zos5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjwhNOvWoiRp",
        "outputId": "1faf810c-3398-4434-bb5b-e95044c896fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = x.to(\"cpu\")\n",
        "x.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAXdPsKbosVI",
        "outputId": "a01616f0-7953-4475-cb15-49986f3ac4f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCSsJDkxpb9Z",
        "outputId": "3b4438bd-d116-4d92-94a4-6fc595f9c167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/drive/MyDrive/data/\""
      ],
      "metadata": {
        "id": "1hf4mglSpOWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from lightgbm import LGBMClassifier\n",
        "df = pd.read_csv(f\"{DATA_PATH}titanic.csv\")\n",
        "# 결측치 미리 채우기\n",
        "df.age = df.age.fillna(df.age.median()) # age 중앙값\n",
        "df.fare = df.fare.fillna(df.fare.median()) # fare 중앙값\n",
        "df.cabin = df.cabin.fillna(\"UNK\") # cabin 임의의 문자열로 채우기\n",
        "df.embarked = df.embarked.fillna(df.embarked.mode()[0]) # embarked 최빈값\n",
        "# 학습에 바로 사용가능한 특성\n",
        "cols = [\"pclass\",\"age\",\"sibsp\",\"parch\",\"fare\"]\n",
        "features = df[cols]\n",
        "# 범주형 one-hot encoding\n",
        "cols = [\"gender\",\"embarked\"]\n",
        "enc = OneHotEncoder()\n",
        "tmp = pd.DataFrame(\n",
        "    enc.fit_transform(df[cols]).toarray(),\n",
        "    columns = enc.get_feature_names_out()\n",
        ")\n",
        "features = pd.concat([features,tmp],axis=1) # 특성\n",
        "target = df[\"survived\"].to_numpy() # 정답값\n",
        "# 스케일링\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "features = scaler.fit_transform(features)\n",
        "SEED = 42\n",
        "# 학습 검증 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(features, target, random_state=SEED)\n",
        "x_train.shape, x_valid.shape, y_train.shape, y_valid.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EFdbNdho0gR",
        "outputId": "d6175240-66a8-4bd5-ff17-0f67e2d9419e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((981, 10), (328, 10), (981,), (328,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset 와 DataLoader\n",
        "- torch.utils.data.Dataset\n",
        "    - 학습데이터와 정답데이터를 인덱싱을 통해 반환하는 클래스\n",
        "- torch.utils.data.DataLoader\n",
        "    - Dataset의 데이터를 쉽게 접근할 수 있도록 iterable한 객체로 만들어준다."
      ],
      "metadata": {
        "id": "BzzQ9aQMrUzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.reshape(-1,1).shape # 파이토치는 최소 2차원이여한다. (텐서는 필요 X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr_R7Jhmw0k_",
        "outputId": "17c1dbf1-9a32-48d0-97e8-e192569252c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(981, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TitanicDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,x,y = None): # 정답데이터가 없을 때를 생각해 None값 넣음\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        if self.y is not None:\n",
        "            self.y = y.reshape(-1,1)\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    def __getitem__(self,idx):\n",
        "        item = {}\n",
        "        item[\"x\"] = torch.Tensor(self.x[idx])\n",
        "        if self.y is not None:\n",
        "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
        "        \n",
        "        return item\n",
        "        # 여기까지 필수적으로 넣어주어야 한다. (Input Layer)"
      ],
      "metadata": {
        "id": "B7wnudTKpM2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dt = TitanicDataset(x_train,y_train)\n",
        "train_dt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWZFzDG3qpal",
        "outputId": "57ea6f02-d33b-4079-b86c-855669954234"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.TitanicDataset at 0x7f5db83685d0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dt[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8BU-AnPyluv",
        "outputId": "bb377449-cd5a-4526-c95b-d8cdc940e15d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([0.5000, 0.3611, 0.1250, 0.0000, 0.0507, 1.0000, 0.0000, 0.0000, 0.0000,\n",
              "         1.0000]), 'y': tensor([1.])}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = torch.utils.data.DataLoader(train_dt,batch_size=2,shuffle=False)\n",
        "train_dl # 예측할 때는 섞지 않고, 학습할 때는 섞기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqPqgmgCzFJL",
        "outputId": "f0d0553d-b577-4968-e36a-1f3df0f8f297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f5db8363cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in train_dl:\n",
        "    print(i)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwhnpzuQzFE3",
        "outputId": "1a04070d-8401-43a2-88b0-d67919bb6bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'x': tensor([[0.5000, 0.3611, 0.1250, 0.0000, 0.0507, 1.0000, 0.0000, 0.0000, 0.0000,\n",
            "         1.0000],\n",
            "        [1.0000, 0.5365, 0.1250, 0.6667, 0.0915, 1.0000, 0.0000, 0.0000, 0.0000,\n",
            "         1.0000]]), 'y': tensor([[1.],\n",
            "        [0.]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dl)) # [\"x\"] # 잘 꺼내지는지 확인할 때 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2enfrylzFDq",
        "outputId": "a0937f98-0fd1-46a7-e817-bdb64c7ef6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': tensor([[0.5000, 0.3611, 0.1250, 0.0000, 0.0507, 1.0000, 0.0000, 0.0000, 0.0000,\n",
              "          1.0000],\n",
              "         [1.0000, 0.5365, 0.1250, 0.6667, 0.0915, 1.0000, 0.0000, 0.0000, 0.0000,\n",
              "          1.0000]]), 'y': tensor([[1.],\n",
              "         [0.]])}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 계층(Layer) 정의해보기\n",
        "- torch.nn.Linear\n",
        "    - 가중치와 편향을 사용해서 입력에 대해 선형변환\n",
        "    - in_features\n",
        "        - 입력값의 개수\n",
        "    - out_features\n",
        "        - 출력값의 개수"
      ],
      "metadata": {
        "id": "0MWcLTdVzEnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ6OfdsU1jp4",
        "outputId": "f2a010fd-d984-4987-f505-e82137f3b895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "input_layer = torch.nn.Linear(x_train.shape[1],1) # 다중 회귀\n",
        "data = next(iter(train_dl))\n",
        "\n",
        "hidden_layer = input_layer(data[\"x\"]) # 학습데이터 x 넣기!\n",
        "hidden_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q2KRvFkzElR",
        "outputId": "b6f6f010-eaed-46a5-f028-36c732c43311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3096],\n",
              "        [0.6673]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 만들기\n",
        "- Pytorch에서 신경망 모델은 torch.nn.Module을 상속받아서 클래스를 생성해서 정의\n",
        "- `__init__`메소드에서는 신경망의 계층들을 정의\n",
        "- `forward` 메소드에서는 신경망에서 텐서를 어떻게 전달할지를 지정"
      ],
      "metadata": {
        "id": "IsGdicVPzEjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self,in_features):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = torch.nn.Linear(in_features,1)\n",
        "        # self.sig = torch.nn.Sigmoid()\n",
        "        # 손실함수에서 시그모이드 함수를 통과시키는 기능이 있어서 따로 해줄 필요가 없다.\n",
        "    def forward(self,x):\n",
        "          x = self.hidden_layer(x)\n",
        "          # x = self.sig(x)\n",
        "          return x  # Hidden layer"
      ],
      "metadata": {
        "id": "lnv8ImWKzEfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(x_train.shape[1]) # SEED 고정을 안해서 값이 다르다.\n",
        "model(data[\"x\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6G-njWIzEdi",
        "outputId": "6939f56b-7258-4f2f-84e9-78ba43ebd766"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0070],\n",
              "        [0.2196]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 학습"
      ],
      "metadata": {
        "id": "0Y28FoHszEbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # 미니 배치 사이즈"
      ],
      "metadata": {
        "id": "qt6oy5SJzET-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 손실함수 객체 생성"
      ],
      "metadata": {
        "id": "JYKe6OM5zER-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "# 시그모이드 통과를 안시켜서 BCELoss 사용 X"
      ],
      "metadata": {
        "id": "sP8ZAvHOzEOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델 객체 생성"
      ],
      "metadata": {
        "id": "Je42OlzFzEMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(x_train.shape[1]).to(device) # GPU로 이동!"
      ],
      "metadata": {
        "id": "cPlBoGPpzEJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- optimizer 객체 생성"
      ],
      "metadata": {
        "id": "ioryj_VTbUKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.001) # lr = 0.001"
      ],
      "metadata": {
        "id": "GAJWowUzbdpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습데이터 객체 생성"
      ],
      "metadata": {
        "id": "xt-_3dOkb5Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dt = TitanicDataset(x_train,y_train)\n",
        "train_dl = torch.utils.data.DataLoader(train_dt,batch_size=batch_size,shuffle=True)"
      ],
      "metadata": {
        "id": "uBRNIJECb4-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습하기"
      ],
      "metadata": {
        "id": "aQeMIEkpb47v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.train() # 명시적으로 해주는 습관을 가지자!\n",
        "\n",
        "epoch_loss = 0\n",
        "for batch in train_dl:\n",
        "    pred = model(batch[\"x\"].to(device)) # GPU 안에 학습데이터를 모델에 넣는다.\n",
        "    loss = loss_fn(pred,batch[\"y\"].to(device)) # 정답값을 옮겨줘 손실값을 계산\n",
        "\n",
        "    optimizer.zero_grad() # 경사를 0으로 초기화하고\n",
        "    loss.backward() # 역전파 실행\n",
        "    optimizer.step() # 업데이트 (다음 3가지는 세트!)\n",
        "\n",
        "    epoch_loss += loss.item() # 값만 가져올 때 item\n",
        "\n",
        "epoch_loss /= len(train_dl)\n",
        "print(f\"epoch loss: {epoch_loss}\")\n",
        "    # print(batch_loss) # 한번의 에폭 종료!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCRrRbGbb4y5",
        "outputId": "16cb3183-20d5-4093-a1ee-4b250938874a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch loss: 0.7615217739535917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 학습 loop 함수화"
      ],
      "metadata": {
        "id": "uKQmEGTcb4uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_dl,model,loss_fn,optimizer,device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for batch in train_dl:\n",
        "        pred = model(batch[\"x\"].to(device))\n",
        "        loss = loss_fn(pred,batch[\"y\"].to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(train_dl)\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "GaBxCoHgb4se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loop(train_dl,model,loss_fn,optimizer,device) # 2번째 에폭"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KERq6go4b4qR",
        "outputId": "cf46d2f5-cb3f-4f9c-ec1b-5cf969d2701c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7423399283039954"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검증셋에 대한 평가 loop 함수화"
      ],
      "metadata": {
        "id": "oeYTua_Yb4hW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # with torch.no_grad():와 같다. 경사하강법에 따른 가중치를 계산하지 않겠다.(메모리도 많이 차지하고, 계산시간도 잡아먹기 때문에)\n",
        "def test_loop(dataloader,model,loss_fn,device):\n",
        "    epoch_loss = 0\n",
        "    model.eval() # 랜덤적인 요소를 없애기 위해 eval을 선언 (layer들을 알아서 off 시키도록 하는 함수)\n",
        "    # eval은 검증이나 테스트에서 선언하는 것! (학습에서는 사용하지 않는다.)\n",
        "    for batch in dataloader:\n",
        "        pred = model(batch[\"x\"].to(device))\n",
        "        loss = loss_fn(pred,batch[\"y\"].to(device))\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "Zv0JBf9gb4ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dt = TitanicDataset(x_valid,y_valid) # 학습데이터를 검증하기 위해서 만듦!\n",
        "valid_dl = torch.utils.data.DataLoader(valid_dt,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "BFJvw0Dhb4Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loop(valid_dl,model,loss_fn,device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JG4JACbPb4LR",
        "outputId": "e9e58e2f-c9d5-4d9d-c307-617f32be774a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7517904259941794"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검증평가뿐만 아니라 테스트데이터에 대한 예측만 해야하는 상황이라면?"
      ],
      "metadata": {
        "id": "WEeJIaetpe3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # with torch.no_grad():와 같다.\n",
        "def test_loop(dataloader,model,loss_fn,device):\n",
        "    epoch_loss = 0\n",
        "    model.eval() # 랜덤적인 요소를 없애기 위해 eval을 선언\n",
        "\n",
        "    pred_list = []\n",
        "    sig = torch.nn.Sigmoid() # 0과 1사이의 확률로 변환\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        pred = model(batch[\"x\"].to(device))\n",
        "\n",
        "        if batch.get(\"y\") is not None: # y값이 있을 경우에만 loss 계산\n",
        "            loss = loss_fn(pred,batch[\"y\"].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        pred = sig(pred) # 시그모이드 함수 통과 0 ~ 1 확률값으로 변경\n",
        "        pred = pred.to(\"cpu\").numpy() # cpu 이동 후 numpy 변환\n",
        "        pred_list.append(pred)\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "\n",
        "    pred = np.concatenate(pred_list) # auc도 볼 수 있다.\n",
        "\n",
        "    return epoch_loss,pred"
      ],
      "metadata": {
        "id": "orzQWHCrb4JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_valid.copy() # 테스트 데이터라고 가정하고 복사"
      ],
      "metadata": {
        "id": "pJSyKJOQb4HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dt = TitanicDataset(x_test)\n",
        "test_dl = torch.utils.data.DataLoader(test_dt,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "_,pred = test_loop(test_dl,model,loss_fn,device)\n",
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3R0QSn-b4En",
        "outputId": "80a383bf-233c-4bd9-854b-89708c25c230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.43548584],\n",
              "       [0.50419056],\n",
              "       [0.43547758],\n",
              "       [0.46744052],\n",
              "       [0.37289846],\n",
              "       [0.26883337],\n",
              "       [0.37289846],\n",
              "       [0.35799813],\n",
              "       [0.31267574],\n",
              "       [0.36820227],\n",
              "       [0.43127477],\n",
              "       [0.43652943],\n",
              "       [0.4395618 ],\n",
              "       [0.3198314 ],\n",
              "       [0.43592188],\n",
              "       [0.35671872],\n",
              "       [0.37021402],\n",
              "       [0.4354708 ],\n",
              "       [0.40801257],\n",
              "       [0.44177526],\n",
              "       [0.4711563 ],\n",
              "       [0.4391496 ],\n",
              "       [0.42718893],\n",
              "       [0.42771393],\n",
              "       [0.4407235 ],\n",
              "       [0.45517012],\n",
              "       [0.43339115],\n",
              "       [0.43762025],\n",
              "       [0.46477994],\n",
              "       [0.32468432],\n",
              "       [0.43568015],\n",
              "       [0.36222067],\n",
              "       [0.3728993 ],\n",
              "       [0.4301358 ],\n",
              "       [0.4976283 ],\n",
              "       [0.4899348 ],\n",
              "       [0.37889856],\n",
              "       [0.3114683 ],\n",
              "       [0.43548125],\n",
              "       [0.32646543],\n",
              "       [0.5025921 ],\n",
              "       [0.33414972],\n",
              "       [0.37290213],\n",
              "       [0.4286808 ],\n",
              "       [0.44236574],\n",
              "       [0.46511748],\n",
              "       [0.42158246],\n",
              "       [0.36934462],\n",
              "       [0.37289846],\n",
              "       [0.3620326 ],\n",
              "       [0.37739867],\n",
              "       [0.33514825],\n",
              "       [0.4349537 ],\n",
              "       [0.47872564],\n",
              "       [0.349303  ],\n",
              "       [0.48993728],\n",
              "       [0.43915334],\n",
              "       [0.32541928],\n",
              "       [0.44062513],\n",
              "       [0.42814994],\n",
              "       [0.5084526 ],\n",
              "       [0.4899348 ],\n",
              "       [0.40815872],\n",
              "       [0.3190734 ],\n",
              "       [0.3355198 ],\n",
              "       [0.5119223 ],\n",
              "       [0.30363154],\n",
              "       [0.34669045],\n",
              "       [0.43391088],\n",
              "       [0.48404935],\n",
              "       [0.43548125],\n",
              "       [0.50238544],\n",
              "       [0.38418955],\n",
              "       [0.43440565],\n",
              "       [0.47679   ],\n",
              "       [0.49866167],\n",
              "       [0.37165326],\n",
              "       [0.43338737],\n",
              "       [0.39098918],\n",
              "       [0.4728841 ],\n",
              "       [0.40015203],\n",
              "       [0.43545574],\n",
              "       [0.44913426],\n",
              "       [0.4605496 ],\n",
              "       [0.43757698],\n",
              "       [0.43548125],\n",
              "       [0.4800082 ],\n",
              "       [0.47759345],\n",
              "       [0.35072693],\n",
              "       [0.37433127],\n",
              "       [0.37289846],\n",
              "       [0.51190704],\n",
              "       [0.43476462],\n",
              "       [0.26385108],\n",
              "       [0.4350056 ],\n",
              "       [0.3413148 ],\n",
              "       [0.43755275],\n",
              "       [0.51178455],\n",
              "       [0.35690072],\n",
              "       [0.32193512],\n",
              "       [0.43860433],\n",
              "       [0.43267074],\n",
              "       [0.43545425],\n",
              "       [0.35061142],\n",
              "       [0.32164198],\n",
              "       [0.3726153 ],\n",
              "       [0.3381732 ],\n",
              "       [0.4925685 ],\n",
              "       [0.44510835],\n",
              "       [0.37289846],\n",
              "       [0.46783704],\n",
              "       [0.3481443 ],\n",
              "       [0.37289846],\n",
              "       [0.42399538],\n",
              "       [0.33891323],\n",
              "       [0.4343613 ],\n",
              "       [0.3734007 ],\n",
              "       [0.30932048],\n",
              "       [0.43286783],\n",
              "       [0.37536448],\n",
              "       [0.42344517],\n",
              "       [0.3575136 ],\n",
              "       [0.37432286],\n",
              "       [0.375341  ],\n",
              "       [0.43355152],\n",
              "       [0.26191267],\n",
              "       [0.31702122],\n",
              "       [0.51259905],\n",
              "       [0.4418274 ],\n",
              "       [0.33041108],\n",
              "       [0.37529913],\n",
              "       [0.33447823],\n",
              "       [0.42550647],\n",
              "       [0.35523534],\n",
              "       [0.47381246],\n",
              "       [0.43448186],\n",
              "       [0.35591498],\n",
              "       [0.43843397],\n",
              "       [0.37932786],\n",
              "       [0.43705463],\n",
              "       [0.4899348 ],\n",
              "       [0.2652999 ],\n",
              "       [0.51078373],\n",
              "       [0.44178358],\n",
              "       [0.4317916 ],\n",
              "       [0.27519158],\n",
              "       [0.41068816],\n",
              "       [0.3304327 ],\n",
              "       [0.37532187],\n",
              "       [0.42209062],\n",
              "       [0.4370343 ],\n",
              "       [0.5083254 ],\n",
              "       [0.43548125],\n",
              "       [0.4993951 ],\n",
              "       [0.27111188],\n",
              "       [0.33614284],\n",
              "       [0.4598863 ],\n",
              "       [0.33400548],\n",
              "       [0.43704635],\n",
              "       [0.31615683],\n",
              "       [0.47107998],\n",
              "       [0.37532178],\n",
              "       [0.43602833],\n",
              "       [0.36753756],\n",
              "       [0.43861628],\n",
              "       [0.42607167],\n",
              "       [0.43809986],\n",
              "       [0.377632  ],\n",
              "       [0.43522227],\n",
              "       [0.4899348 ],\n",
              "       [0.36991674],\n",
              "       [0.32427007],\n",
              "       [0.4336384 ],\n",
              "       [0.36036962],\n",
              "       [0.51164836],\n",
              "       [0.40918887],\n",
              "       [0.3154021 ],\n",
              "       [0.37219188],\n",
              "       [0.4936659 ],\n",
              "       [0.4356233 ],\n",
              "       [0.43548584],\n",
              "       [0.4899348 ],\n",
              "       [0.3255464 ],\n",
              "       [0.33509845],\n",
              "       [0.32431486],\n",
              "       [0.43547758],\n",
              "       [0.48405376],\n",
              "       [0.4736782 ],\n",
              "       [0.31602153],\n",
              "       [0.4354708 ],\n",
              "       [0.47479898],\n",
              "       [0.37839663],\n",
              "       [0.4365903 ],\n",
              "       [0.42427507],\n",
              "       [0.45095786],\n",
              "       [0.44075108],\n",
              "       [0.3598333 ],\n",
              "       [0.37289846],\n",
              "       [0.4732811 ],\n",
              "       [0.5116292 ],\n",
              "       [0.42749384],\n",
              "       [0.32490587],\n",
              "       [0.3428022 ],\n",
              "       [0.4716111 ],\n",
              "       [0.29583988],\n",
              "       [0.4297274 ],\n",
              "       [0.47420958],\n",
              "       [0.43762136],\n",
              "       [0.4347695 ],\n",
              "       [0.43940008],\n",
              "       [0.47434387],\n",
              "       [0.4086376 ],\n",
              "       [0.5176229 ],\n",
              "       [0.426343  ],\n",
              "       [0.46723914],\n",
              "       [0.43278703],\n",
              "       [0.33134124],\n",
              "       [0.36079842],\n",
              "       [0.43602833],\n",
              "       [0.51164836],\n",
              "       [0.4412765 ],\n",
              "       [0.37046114],\n",
              "       [0.4460861 ],\n",
              "       [0.37290955],\n",
              "       [0.4365258 ],\n",
              "       [0.34666976],\n",
              "       [0.4616088 ],\n",
              "       [0.37932795],\n",
              "       [0.46895632],\n",
              "       [0.43495607],\n",
              "       [0.27421373],\n",
              "       [0.42759517],\n",
              "       [0.4107651 ],\n",
              "       [0.3983305 ],\n",
              "       [0.35935315],\n",
              "       [0.46903256],\n",
              "       [0.35824364],\n",
              "       [0.4728841 ],\n",
              "       [0.32658753],\n",
              "       [0.4292043 ],\n",
              "       [0.50044394],\n",
              "       [0.48833653],\n",
              "       [0.43495825],\n",
              "       [0.4123047 ],\n",
              "       [0.43338737],\n",
              "       [0.31203598],\n",
              "       [0.47060314],\n",
              "       [0.43705076],\n",
              "       [0.35158256],\n",
              "       [0.3117158 ],\n",
              "       [0.49427977],\n",
              "       [0.3728981 ],\n",
              "       [0.47385198],\n",
              "       [0.39826697],\n",
              "       [0.30668637],\n",
              "       [0.32274485],\n",
              "       [0.44317698],\n",
              "       [0.50738215],\n",
              "       [0.26385108],\n",
              "       [0.37187928],\n",
              "       [0.35157466],\n",
              "       [0.35939562],\n",
              "       [0.3432984 ],\n",
              "       [0.46845293],\n",
              "       [0.37589374],\n",
              "       [0.32776892],\n",
              "       [0.31902608],\n",
              "       [0.44109392],\n",
              "       [0.38268387],\n",
              "       [0.4899103 ],\n",
              "       [0.43814296],\n",
              "       [0.43352023],\n",
              "       [0.34666976],\n",
              "       [0.4509284 ],\n",
              "       [0.4728841 ],\n",
              "       [0.43441412],\n",
              "       [0.4143724 ],\n",
              "       [0.4404246 ],\n",
              "       [0.51176924],\n",
              "       [0.396322  ],\n",
              "       [0.43547156],\n",
              "       [0.50985473],\n",
              "       [0.4355043 ],\n",
              "       [0.46478856],\n",
              "       [0.4235778 ],\n",
              "       [0.43756622],\n",
              "       [0.42503092],\n",
              "       [0.49673092],\n",
              "       [0.31964877],\n",
              "       [0.31733948],\n",
              "       [0.4673916 ],\n",
              "       [0.4270486 ],\n",
              "       [0.37444106],\n",
              "       [0.37757322],\n",
              "       [0.38034046],\n",
              "       [0.450522  ],\n",
              "       [0.37889808],\n",
              "       [0.3229941 ],\n",
              "       [0.43187547],\n",
              "       [0.3114683 ],\n",
              "       [0.39123285],\n",
              "       [0.35619268],\n",
              "       [0.34516266],\n",
              "       [0.4899348 ],\n",
              "       [0.43027195],\n",
              "       [0.3379482 ],\n",
              "       [0.46580026],\n",
              "       [0.3295521 ],\n",
              "       [0.47275877],\n",
              "       [0.51046884],\n",
              "       [0.46680328],\n",
              "       [0.3731137 ],\n",
              "       [0.44184995],\n",
              "       [0.37289846],\n",
              "       [0.47221857],\n",
              "       [0.4386276 ],\n",
              "       [0.37581468],\n",
              "       [0.30725425],\n",
              "       [0.43757826],\n",
              "       [0.31267574],\n",
              "       [0.32321426],\n",
              "       [0.37391037],\n",
              "       [0.4211513 ],\n",
              "       [0.384927  ],\n",
              "       [0.3363787 ],\n",
              "       [0.3377679 ],\n",
              "       [0.43569824],\n",
              "       [0.26402038]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10 에폭 학습하고 검증평가해보기"
      ],
      "metadata": {
        "id": "JGta4Asgb0Bt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    print(f\"{epoch+1} epoch 시작\")\n",
        "    train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
        "    valid_loss, pred = test_loop(valid_dl, model, loss_fn, device)\n",
        "    print(train_loss,valid_loss) # 적절한 에폭 선택으로 오버피팅을 방지"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz1hMiV3tWb4",
        "outputId": "092418f6-9925-43f6-bbcc-50f1af4801bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 epoch 시작\n",
            "0.7284330033486889 0.7388763644478538\n",
            "2 epoch 시작\n",
            "0.7147180226541334 0.7264711911028082\n",
            "3 epoch 시작\n",
            "0.7007835603529408 0.7149528319185431\n",
            "4 epoch 시작\n",
            "0.6898600939781435 0.7038845907558094\n",
            "5 epoch 시작\n",
            "0.6781554568198419 0.6928930553522977\n",
            "6 epoch 시작\n",
            "0.6673279058548712 0.682576445015994\n",
            "7 epoch 시작\n",
            "0.6592964856855331 0.6726287711750377\n",
            "8 epoch 시작\n",
            "0.6484159096594779 0.6627776189283892\n",
            "9 epoch 시작\n",
            "0.6379899747910038 0.6531625660982999\n",
            "10 epoch 시작\n",
            "0.6300130005805723 0.6440484957261519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_valid,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzQmdNCMufdr",
        "outputId": "03790465-f05c-4b1c-9950-c4278c3065ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7694036501724338"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정리해보자"
      ],
      "metadata": {
        "id": "ScW_hh_rtrNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## dataset 정의"
      ],
      "metadata": {
        "id": "MnhgFCZ9u4Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TitanicDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,x,y = None): # 정답데이터가 없을 때를 생각해 None값 넣음\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        if self.y is not None:\n",
        "            self.y = y.reshape(-1,1)\n",
        "    def __len__(self):\n",
        "        return self.x.shape[0]\n",
        "    def __getitem__(self,idx): # 슬라이싱을 하기 위해 쓰임\n",
        "        item = {}\n",
        "        item[\"x\"] = torch.Tensor(self.x[idx])\n",
        "        if self.y is not None:\n",
        "            item[\"y\"] = torch.Tensor(self.y[idx])\n",
        "        \n",
        "        return item\n",
        "        # 여기까지 필수적으로 넣어주어야 한다. (Input Layer)"
      ],
      "metadata": {
        "id": "O-y8Rw9Gu9u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 정의"
      ],
      "metadata": {
        "id": "p1HxwOhNvHID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression(torch.nn.Module):\n",
        "    def __init__(self,in_features):\n",
        "        super().__init__()\n",
        "        self.hidden_layer = torch.nn.Linear(in_features,1)\n",
        "        # self.sig = torch.nn.Sigmoid()\n",
        "        # 손실함수에서 시그모이드 함수를 통과시키는 기능이 있어서 따로 해줄 필요가 없다.\n",
        "    def forward(self,x):\n",
        "          x = self.hidden_layer(x)\n",
        "          # x = self.sig(x)\n",
        "          return x  # Hidden layer"
      ],
      "metadata": {
        "id": "i3ZTLm6hvHMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습하는 함수 정의"
      ],
      "metadata": {
        "id": "2-AzI2W2vHSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(train_dl,model,loss_fn,optimizer,device):\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "    for batch in train_dl:\n",
        "        pred = model(batch[\"x\"].to(device))\n",
        "        loss = loss_fn(pred,batch[\"y\"].to(device))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(train_dl)\n",
        "\n",
        "    return epoch_loss"
      ],
      "metadata": {
        "id": "YdIh0544vHXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가 or 예측하는 함수정의"
      ],
      "metadata": {
        "id": "krhjFB7svHcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # with torch.no_grad():와 같다.\n",
        "def test_loop(dataloader,model,loss_fn,device):\n",
        "    epoch_loss = 0\n",
        "    model.eval() # 랜덤적인 요소를 없애기 위해 eval을 선언\n",
        "\n",
        "    pred_list = []\n",
        "    sig = torch.nn.Sigmoid()\n",
        "    \n",
        "    for batch in dataloader:\n",
        "        pred = model(batch[\"x\"].to(device))\n",
        "\n",
        "        if batch.get(\"y\") is not None: # y값이 있을 경우에만 loss 계산(검증평가를 할 경우만 계산하고 싶을 때)\n",
        "            loss = loss_fn(pred,batch[\"y\"].to(device))\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        pred = sig(pred) # 시그모이드 함수 통과 0 ~ 1 확률값으로 변경\n",
        "        pred = pred.to(\"cpu\").numpy() # cpu 이동 후 numpy 변환\n",
        "        pred_list.append(pred)\n",
        "\n",
        "    epoch_loss /= len(dataloader)\n",
        "\n",
        "    pred = np.concatenate(pred_list) # auc도 볼 수 있다.\n",
        "\n",
        "    return epoch_loss,pred"
      ],
      "metadata": {
        "id": "IrjcDzxqvHh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습에 필요한 손실과 최적화 등 하이퍼 파라미터 정의"
      ],
      "metadata": {
        "id": "T4l4kETSvHnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "epoch = 1000\n",
        "batch_size = 32 # 8 16 32 64 이렇게 넣어주는 것이 좋다.\n",
        "num_features = x_train.shape[1]"
      ],
      "metadata": {
        "id": "beYDtb0zvHr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "cv = KFold(n_splits = 5, shuffle = True, random_state = SEED)"
      ],
      "metadata": {
        "id": "A7wPu5oTvHxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.shape, target.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQKzdBMwvH_0",
        "outputId": "5604d972-3690-4f8a-c0f3-4486f4ad87be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1309, 10), (1309,))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "is_holdout = True # 홀드아웃 첫번째 홀드만하고 빠져나옴!(True, False 왔다갔다 쓰기) => 시간을 아끼기 위해 성능이 좋아질 때 5번 다돌림\n",
        "for tri,vai in cv.split(features):\n",
        "    # 학습 데이터\n",
        "    x_train = features[tri]\n",
        "    y_train = target[tri]\n",
        "\n",
        "    # 검증 데이터\n",
        "    x_valid = features[vai]\n",
        "    y_valid = target[vai]\n",
        "\n",
        "    model = LogisticRegression(num_features).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    train_dt = TitanicDataset(x_train,y_train)\n",
        "    valid_dt = TitanicDataset(x_valid,y_valid)\n",
        "\n",
        "    train_dl = torch.utils.data.DataLoader(train_dt,batch_size=batch_size,shuffle=True)\n",
        "    valid_dl = torch.utils.data.DataLoader(valid_dt,batch_size=batch_size,shuffle=False)\n",
        "    \n",
        "    train_loss_history = []\n",
        "    valid_loss_history = []\n",
        "\n",
        "    for e in range(epoch):\n",
        "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
        "        valid_loss,pred = test_loop(valid_dl, model, loss_fn, device)\n",
        "\n",
        "        train_loss_history.append(train_loss) # 그래프 그리기!\n",
        "        valid_loss_history.append(valid_loss)\n",
        "\n",
        "    if is_holdout:\n",
        "        break"
      ],
      "metadata": {
        "id": "tp1tBysHvIUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시각화 해보기"
      ],
      "metadata": {
        "id": "krtTEC07mYHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig,ax = plt.subplots()\n",
        "\n",
        "ax.plot(train_loss_history)\n",
        "ax.plot(valid_loss_history)\n",
        "ax.set_xlabel(\"epochs\")\n",
        "ax.set_ylabel(\"loss value\")\n",
        "ax.legend([\"train\",\"valid\"])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JwFgYpViSixX",
        "outputId": "025eeb1e-0648-4d53-e487-e16d2fb78d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 검증셋 평가 및 검증셋에 대한 AUC 개선이 없을 경우 조기 종료 조건을 주고, 모델 가중치를 저장하기"
      ],
      "metadata": {
        "id": "7uMh7SrCWRrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_holdout = False # 홀드아웃 첫번째 홀드만하고 빠져나옴!(True, False 왔다갔다 쓰기) => 시간을 아끼기 위해 성능이 좋아질 때 5번 다돌림\n",
        "for i,(tri,vai) in enumerate(cv.split(features)):\n",
        "    # 학습 데이터\n",
        "    x_train = features[tri]\n",
        "    y_train = target[tri]\n",
        "\n",
        "    # 검증 데이터\n",
        "    x_valid = features[vai]\n",
        "    y_valid = target[vai]\n",
        "\n",
        "    model = LogisticRegression(num_features).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "    train_dt = TitanicDataset(x_train,y_train)\n",
        "    valid_dt = TitanicDataset(x_valid,y_valid)\n",
        "\n",
        "    train_dl = torch.utils.data.DataLoader(train_dt,batch_size=batch_size,shuffle=True)\n",
        "    valid_dl = torch.utils.data.DataLoader(valid_dt,batch_size=batch_size,shuffle=False)\n",
        "\n",
        "    best_score = 0\n",
        "    patience = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        train_loss = train_loop(train_dl, model, loss_fn, optimizer, device)\n",
        "        valid_loss,pred = test_loop(valid_dl, model, loss_fn, device)\n",
        "\n",
        "        score = roc_auc_score(y_valid,pred) # 현재 에폭에 검증셋에 대한 AUC\n",
        "        patience =+ 1\n",
        "        if best_score < score:\n",
        "            patience = 0 # 최고점수 갱신 했으니 초기화\n",
        "            best_score = score\n",
        "            torch.save(model.state_dict(),f\"model_{i}.pth\") # 최고점수가 갱신되면 덮어씌운다.\n",
        "\n",
        "        if patience == 5: # 5인 경우 멈춰라!\n",
        "            break\n",
        "    print(f\"{i} 번째 폴드 AUC: {best_score}\") # 폴드별 AUC 스코어라 점수가 다르다.\n",
        "\n",
        "    if is_holdout:\n",
        "        break # 저장해야 재현성이 보장된다. (파일을 제출)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIWSbG8pSivV",
        "outputId": "e2f7dc9c-6f7b-4ba8-ed9a-a223770b4585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 번째 폴들 AUC: 0.8863344934969775\n",
            "1 번째 폴들 AUC: 0.9104229417670683\n",
            "2 번째 폴들 AUC: 0.8819743830053108\n",
            "3 번째 폴들 AUC: 0.9090992647058824\n",
            "4 번째 폴들 AUC: 0.8934974747474748\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape # 정답이 없는 테스트 셋이라 가정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KydJib2eqkI",
        "outputId": "a893ab2d-0637-4f84-f0cb-d0931eccb9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(328, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 저장된 모델 불러오고 추론하기"
      ],
      "metadata": {
        "id": "kfMCyLNaeqiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_dt = TitanicDataset(x_test)\n",
        "test_dl = torch.utils.data.DataLoader(test_dt,batch_size=batch_size,shuffle = False)"
      ],
      "metadata": {
        "id": "ZawUCYvGeqgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_list = []\n",
        "for i in range(5):\n",
        "    model = LogisticRegression(num_features).to(device)\n",
        "    state_dict = torch.load(f\"model_{i}.pth\") # 가중치 로드됨!\n",
        "    model.load_state_dict(state_dict)\n",
        "    _,pred = test_loop(test_dl,model,loss_fn,device)\n",
        "    pred_list.append(pred)\n",
        "pred = np.mean(pred_list,axis=0) # 5개의 모델에 대한 산술평균 앙상블\n",
        "pred # 제출!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZZiJfsweqdw",
        "outputId": "44d79a72-528c-4cc5-c62d-d0ce3fc9aaec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08533058],\n",
              "       [0.22296019],\n",
              "       [0.08528741],\n",
              "       [0.12948053],\n",
              "       [0.7708715 ],\n",
              "       [0.74885046],\n",
              "       [0.7708715 ],\n",
              "       [0.83698016],\n",
              "       [0.67536837],\n",
              "       [0.10031857],\n",
              "       [0.07626975],\n",
              "       [0.08779814],\n",
              "       [0.27049053],\n",
              "       [0.9023609 ],\n",
              "       [0.08763321],\n",
              "       [0.84494674],\n",
              "       [0.74032766],\n",
              "       [0.08525212],\n",
              "       [0.17055663],\n",
              "       [0.10197818],\n",
              "       [0.14411987],\n",
              "       [0.09450355],\n",
              "       [0.06706679],\n",
              "       [0.06789369],\n",
              "       [0.09888658],\n",
              "       [0.5373607 ],\n",
              "       [0.08066011],\n",
              "       [0.0842128 ],\n",
              "       [0.12657051],\n",
              "       [0.716063  ],\n",
              "       [0.0863491 ],\n",
              "       [0.85189533],\n",
              "       [0.7708821 ],\n",
              "       [0.07638814],\n",
              "       [0.23131159],\n",
              "       [0.10780396],\n",
              "       [0.8025549 ],\n",
              "       [0.592561  ],\n",
              "       [0.08530638],\n",
              "       [0.79086775],\n",
              "       [0.21318181],\n",
              "       [0.792878  ],\n",
              "       [0.77091837],\n",
              "       [0.07151088],\n",
              "       [0.30994862],\n",
              "       [0.11402686],\n",
              "       [0.05688124],\n",
              "       [0.09874275],\n",
              "       [0.7708715 ],\n",
              "       [0.85279787],\n",
              "       [0.7952671 ],\n",
              "       [0.9326962 ],\n",
              "       [0.0840819 ],\n",
              "       [0.22943623],\n",
              "       [0.8255272 ],\n",
              "       [0.10781921],\n",
              "       [0.09452529],\n",
              "       [0.7237713 ],\n",
              "       [0.11040698],\n",
              "       [0.07056614],\n",
              "       [0.25103223],\n",
              "       [0.10780396],\n",
              "       [0.85684794],\n",
              "       [0.6885589 ],\n",
              "       [0.9270217 ],\n",
              "       [0.27757627],\n",
              "       [0.89503133],\n",
              "       [0.81766415],\n",
              "       [0.08177093],\n",
              "       [0.0799965 ],\n",
              "       [0.08530638],\n",
              "       [0.21226947],\n",
              "       [0.15005252],\n",
              "       [0.08727597],\n",
              "       [0.18090248],\n",
              "       [0.18210293],\n",
              "       [0.7634591 ],\n",
              "       [0.0806416 ],\n",
              "       [0.91427183],\n",
              "       [0.1499362 ],\n",
              "       [0.9219173 ],\n",
              "       [0.08517374],\n",
              "       [0.33863524],\n",
              "       [0.10716458],\n",
              "       [0.09039343],\n",
              "       [0.08530638],\n",
              "       [0.19561216],\n",
              "       [0.19324909],\n",
              "       [0.8345725 ],\n",
              "       [0.8347397 ],\n",
              "       [0.7708715 ],\n",
              "       [0.27736932],\n",
              "       [0.07878798],\n",
              "       [0.772105  ],\n",
              "       [0.08434906],\n",
              "       [0.80993986],\n",
              "       [0.09025969],\n",
              "       [0.27571723],\n",
              "       [0.82049525],\n",
              "       [0.89744127],\n",
              "       [0.09298526],\n",
              "       [0.07465392],\n",
              "       [0.08516592],\n",
              "       [0.7983998 ],\n",
              "       [0.6933564 ],\n",
              "       [0.10137285],\n",
              "       [0.93056   ],\n",
              "       [0.18927094],\n",
              "       [0.12724438],\n",
              "       [0.7708715 ],\n",
              "       [0.1325147 ],\n",
              "       [0.7722763 ],\n",
              "       [0.7708715 ],\n",
              "       [0.06405508],\n",
              "       [0.931197  ],\n",
              "       [0.10509765],\n",
              "       [0.77380306],\n",
              "       [0.6631328 ],\n",
              "       [0.07955499],\n",
              "       [0.11568924],\n",
              "       [0.06319772],\n",
              "       [0.85379535],\n",
              "       [0.11231945],\n",
              "       [0.1155242 ],\n",
              "       [0.07462291],\n",
              "       [0.7800948 ],\n",
              "       [0.72753567],\n",
              "       [0.125177  ],\n",
              "       [0.10230209],\n",
              "       [0.9121726 ],\n",
              "       [0.11523004],\n",
              "       [0.9383875 ],\n",
              "       [0.08704008],\n",
              "       [0.82177716],\n",
              "       [0.15582752],\n",
              "       [0.08316571],\n",
              "       [0.82425326],\n",
              "       [0.24243549],\n",
              "       [0.12899117],\n",
              "       [0.08908997],\n",
              "       [0.10780396],\n",
              "       [0.7458987 ],\n",
              "       [0.27198327],\n",
              "       [0.10202973],\n",
              "       [0.07727443],\n",
              "       [0.8430157 ],\n",
              "       [0.194742  ],\n",
              "       [0.9539741 ],\n",
              "       [0.11538965],\n",
              "       [0.26054305],\n",
              "       [0.08897932],\n",
              "       [0.24635327],\n",
              "       [0.08530638],\n",
              "       [0.19487931],\n",
              "       [0.7804567 ],\n",
              "       [0.93118554],\n",
              "       [0.10668875],\n",
              "       [0.9400083 ],\n",
              "       [0.08904488],\n",
              "       [0.6695508 ],\n",
              "       [0.14348435],\n",
              "       [0.1153888 ],\n",
              "       [0.08666091],\n",
              "       [0.7055621 ],\n",
              "       [0.09305306],\n",
              "       [0.07428598],\n",
              "       [0.09172734],\n",
              "       [0.79632074],\n",
              "       [0.07955812],\n",
              "       [0.10780396],\n",
              "       [0.08996964],\n",
              "       [0.7132605 ],\n",
              "       [0.25866777],\n",
              "       [0.8502391 ],\n",
              "       [0.27388653],\n",
              "       [0.8600891 ],\n",
              "       [0.6437202 ],\n",
              "       [0.11115865],\n",
              "       [0.12027504],\n",
              "       [0.285948  ],\n",
              "       [0.08533058],\n",
              "       [0.10780396],\n",
              "       [0.73887527],\n",
              "       [0.92794037],\n",
              "       [0.91212523],\n",
              "       [0.08528741],\n",
              "       [0.12956102],\n",
              "       [0.15693411],\n",
              "       [0.7191678 ],\n",
              "       [0.08525212],\n",
              "       [0.16011718],\n",
              "       [0.8001486 ],\n",
              "       [0.09216261],\n",
              "       [0.06387703],\n",
              "       [0.0844061 ],\n",
              "       [0.09905274],\n",
              "       [0.84097207],\n",
              "       [0.7708715 ],\n",
              "       [0.15339938],\n",
              "       [0.27363005],\n",
              "       [0.19827993],\n",
              "       [0.71950936],\n",
              "       [0.775444  ],\n",
              "       [0.14573121],\n",
              "       [0.6087739 ],\n",
              "       [0.07339425],\n",
              "       [0.15941039],\n",
              "       [0.09063853],\n",
              "       [0.23535228],\n",
              "       [0.09595851],\n",
              "       [0.1582998 ],\n",
              "       [0.17405853],\n",
              "       [0.3604657 ],\n",
              "       [0.21491113],\n",
              "       [0.12087937],\n",
              "       [0.07518335],\n",
              "       [0.79671055],\n",
              "       [0.8444996 ],\n",
              "       [0.08666091],\n",
              "       [0.27388653],\n",
              "       [0.10058242],\n",
              "       [0.74376696],\n",
              "       [0.4193551 ],\n",
              "       [0.7710117 ],\n",
              "       [0.08777862],\n",
              "       [0.7746842 ],\n",
              "       [0.11022164],\n",
              "       [0.12899211],\n",
              "       [0.1349119 ],\n",
              "       [0.08409415],\n",
              "       [0.7979561 ],\n",
              "       [0.0695408 ],\n",
              "       [0.04274579],\n",
              "       [0.924516  ],\n",
              "       [0.8673191 ],\n",
              "       [0.1355128 ],\n",
              "       [0.85087615],\n",
              "       [0.1499362 ],\n",
              "       [0.9021969 ],\n",
              "       [0.07244326],\n",
              "       [0.20061085],\n",
              "       [0.10298958],\n",
              "       [0.0841051 ],\n",
              "       [0.20416565],\n",
              "       [0.0806416 ],\n",
              "       [0.88763535],\n",
              "       [0.1417242 ],\n",
              "       [0.08906877],\n",
              "       [0.80364925],\n",
              "       [0.5997924 ],\n",
              "       [0.17006616],\n",
              "       [0.77086705],\n",
              "       [0.14487848],\n",
              "       [0.9274023 ],\n",
              "       [0.6971711 ],\n",
              "       [0.7180509 ],\n",
              "       [0.2926697 ],\n",
              "       [0.24368612],\n",
              "       [0.772105  ],\n",
              "       [0.7646685 ],\n",
              "       [0.8126127 ],\n",
              "       [0.83952653],\n",
              "       [0.75221336],\n",
              "       [0.1256347 ],\n",
              "       [0.7875065 ],\n",
              "       [0.7640128 ],\n",
              "       [0.7135908 ],\n",
              "       [0.1050398 ],\n",
              "       [0.8886925 ],\n",
              "       [0.10764994],\n",
              "       [0.09196901],\n",
              "       [0.07211059],\n",
              "       [0.7746842 ],\n",
              "       [0.3530609 ],\n",
              "       [0.1499362 ],\n",
              "       [0.08282242],\n",
              "       [0.21640305],\n",
              "       [0.10253231],\n",
              "       [0.27551115],\n",
              "       [0.9010566 ],\n",
              "       [0.08525605],\n",
              "       [0.11601196],\n",
              "       [0.08542678],\n",
              "       [0.12019123],\n",
              "       [0.07377008],\n",
              "       [0.0903338 ],\n",
              "       [0.06556875],\n",
              "       [0.18090199],\n",
              "       [0.7212329 ],\n",
              "       [0.9236231 ],\n",
              "       [0.12196261],\n",
              "       [0.1936073 ],\n",
              "       [0.11708935],\n",
              "       [0.12277086],\n",
              "       [0.86002207],\n",
              "       [0.35054523],\n",
              "       [0.80254954],\n",
              "       [0.89376336],\n",
              "       [0.07246794],\n",
              "       [0.592561  ],\n",
              "       [0.91411746],\n",
              "       [0.82739973],\n",
              "       [0.7784733 ],\n",
              "       [0.10780396],\n",
              "       [0.07446289],\n",
              "       [0.93508303],\n",
              "       [0.11672585],\n",
              "       [0.7115828 ],\n",
              "       [0.14018613],\n",
              "       [0.1182063 ],\n",
              "       [0.11733538],\n",
              "       [0.10266767],\n",
              "       [0.27353832],\n",
              "       [0.7708715 ],\n",
              "       [0.14867379],\n",
              "       [0.09311732],\n",
              "       [0.85951644],\n",
              "       [0.70290786],\n",
              "       [0.09040035],\n",
              "       [0.67536837],\n",
              "       [0.7216866 ],\n",
              "       [0.81230867],\n",
              "       [0.0572499 ],\n",
              "       [0.9039718 ],\n",
              "       [0.94118595],\n",
              "       [0.7569515 ],\n",
              "       [0.08644446],\n",
              "       [0.7746857 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    }
  ]
}